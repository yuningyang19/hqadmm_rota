function [U,sigma_array,output] = hq_admm_robust_orthogonal_approx(T,U0,sigma_array,options)
% half-quadratic ADMM for robust tensor approximation of order d, where the last t latent factor
% matrices are assumed to be columnwisely orthonormal.
% The noisy model is given by
% A = [sigma;U_1,...,U_d] + N,
% where N represents the heavy-tailed noise or outilers. Gaussian noise is
% also possible. The optimization model is formulated as
% min Phi(A-[sigma;U_1,...,U_d]) s.t. U_j^TU_j=I, j=d-t+1,...,d,
% ||u_{j,i}||=1, j=1,...,d-t,i=1,...,R;
% here Phi(A-[sigma;U_1,...,U_d]) = sum^{n1,...,nd}_{i1=1,...,id=1}
% delta^2/2*log(1+ (A_{i1...id} - [sigma;U_1,...,U_d])_{i1...id})^2 /
% delta^2)
% is a Cauchy loss based cost function.
%
% Parameters and variables:
% The augmented Lagrangian fuction
% L_tau(sigma,U,P,W) = || sqrt(W).*(P-A)||^2 - <Y,[sigma;U] - P> + tau/2 || [sigma;U] - P||^2
% P is the auxiliary variable, and Y is the dual variable
%   [U,sigma_array,output] = hq_admm_robust_orthogonal_approx(T,U0,sigma_array,options)
%   computes the factor matrices
%   U{1}, ..., U{d} and the coefficient sigma => [sigma;U].
%     The algorithm is initialized with the factor matrices U0{n} and sigma_array.
%   The structure output returns additional information:
%

%      U                 - factor matrices.
%      sigma_array       - sigma.
%      output.iterations - The number of iterations.
%      output.relstep    - successive relative difference.
%      
%
%    options:
%      options.e1 and optoins.e2
%                                  - The perturbation parameters. Should be
%                                     nonnegative. default 10^{-8}
%      options.delta               - The scale parameter of the Cauchy loss
%                                     default 0.05.
%      options.loss_weight         - The weight of the HQ property
%                                     (function handle)
%                                     generated by a loss. 
%                                     default = @cauchy.
%      options.tau                 - The augmented parameter. Should be
%                                     positive. default 1.
%      options.max_iter = 2000      - The maximum number of iterations.
%      options.tol_relstep                - The tolerance for output.relstep.
%                                     default 10^{-6}.

%   Author: Yuning Yang (yyang@gxu.edu.cn) and Yunlong Feng
% Y. Yang and Y. Feng, Half-Quadratic Alternating Direction Method of
%                       Multipliers for Robust Orthogonal Tensor Approximation
%                   http://arxiv.org/abs/1911.10921
addpath ../loss
d = ndims(T);
if d < 3, error('the order should be >= 3.'); end
if ~isfield(options,'t'),  error('there should be at least one factor matrix being columnwise orthogonal.');    end
t = options.t;
% Check the initial factor matrices U0.
U = U0(:).';
R = size(U{1},2);
if any(cellfun('size',U,2) ~= R)
    error('all factor matrices should have the same column size.');
end
if any(cellfun('size',U,1) ~= size(T))
    error('the row size of the factor matrices should be equal to the size of the data tensor.');
end
if ~isfield(options,'max_iter'), options.max_iter = 2000; end
if ~isfield(options,'tol_relstep'), options.tol_relstep = 1e-6; end
if ~isfield(options,'delta'), options.delta = 0.05; end
if ~isfield(options,'tau'), options.tau = 1; end
if ~isfield(options,'e1'), options.e1 = 10^(-8); end
if ~isfield(options,'e2'), options.e2 = 10^(-8); end
if ~isfield(options,'loss_weight'), options.loss_weight = @cauchy; end
tau = options.tau;
delta = options.delta;
e1 = options.e1;
e2 = options.e2;
loss_weight = options.loss_weight;
E = ones(size(T));
W = E;      
P = T; Y = randn(size(T));
output.info = false;
output.iterations = 0;
output.relerr = []; output.relerr(1) = 1;
while ~output.info
    
    % Save current iterate.
    U1 = U;
    for n = 1: d-t          % Update non-orthogonal factor matrices.
        krUn = kr(U([d:-1:n+1 n-1:-1:1])); % KR product of the other factor matrices.
        Tn = tens2mat(Y+tau*P,n);        % the mode-n unfolding of the tensor Y+tau*P: n_1\times produ_{j\neq 1}n_j
        Vn = Tn*krUn;      % line 4 of the paper, update the V_j's simultaneously by using KR prod..
        tilde_Vn = Vn*diag(sigma_array) + e1*U{n};    % line 5 of the paper. Omega = diag(omega_i^k)
        col_norm_Vn = sum(abs(tilde_Vn).^2).^(1/2);   % norm of each column of tilde_Vn -> ||tilde_Vn_i||=1
        U{n} = tilde_Vn*diag( 1./col_norm_Vn  );        %   every column of t_Vn should be normalized.
    end
    for n = d-t+1: d %   Factors related to polar decomp.
        krUn = kr(U([d:-1:n+1 n-1:-1:1])); % KR product of the other factor matrices.
        Tn = tens2mat(Y+tau*P,n);        % the mode-n unfolding of the tensor Y+tau*P: n_1\times produ_{j\neq 1}n_j
        Vn = Tn*krUn;      %   update the V_j's simultaneously by using KR prod..
        tilde_Vn = Vn*diag(sigma_array)  + e2*U{n};    % line 5 of the paper. Omega = diag(omega_i^k)
        U{n} = polar_decomp(tilde_Vn);
    end
    % update sigma min tau/2 <sigma,sigma> - <Y + tau*P,sum sigma_i* u_i1
    % circ \cdots circ u_id> => sigma_i = <Y + tau*P,u_i1 circ cdots circ
    % u_id>/tau
    sigma_array = dot(U{n},Vn)/tau;      % the <U{n}_i,Vn_i>/tau is exactly sigma_i, if n=1.    
    % update P min || sqrt(W).*(P-T)||^2 + <Y,P> + tau/2||P-[sigma;U]||^2
    % => 2W.*(P-T) + Y + tau*(P-[sigma;U])=0
    % => P = (2W.*T - Y + tau[sigma;U] ) ./ (2W+E)
    U0 = U; U0{1} = U0{1}*diag(sigma_array); est_T = cpdgen(U0);
    P = (2*W.*T - Y + tau*est_T ) ./ (2.*W+E);   
    % update Y
    Y = Y - tau*(est_T-P);    
    % update W
%     W =   (      delta^2 ./ ( delta^2 + (T - P).^2   ) );
    W = loss_weight(T,P,delta);
    
    output.iterations = output.iterations+1;
    output.relerr(end+1) = frob(est_T -T );
    if abs(output.relerr(end)-output.relerr(end-1)  )  <= options.tol_relstep, output.info = 1; end
    if output.iterations >= options.max_iter, output.info = 2; end
    
    %     fprintf('\b\b\b\b\b%5i',output.iterations);
end





